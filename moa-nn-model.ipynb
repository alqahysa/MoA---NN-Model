{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.feature_selection import VarianceThreshold# Input data files are available in the read-only \"../input/\" directory\nimport keras\nfrom keras.models import Sequential\nfrom keras.optimizers import SGD\nfrom keras import layers \nfrom keras.layers import Activation, Dense ,Dropout, BatchNormalization, Input,LeakyReLU\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import log_loss\nfrom sklearn import preprocessing\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.models as M\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Mechanisms of Action (MoA) Prediction\n\nThe goal of the challenge is to classify drugs based on their biological activity to identify certain proteins that are associated with a specific disease and then develop molecules that can target those proteins.\n\nThe data set describes the responses of 100 different types of human cells to various drugs. These response patterns will be used to classify the response of the MoA.\n\nIt is a multi-tag classification problem. Drugs can have multiple MoA annotations that describe binary responses from different cell types in different ways. The evaluation metric is the mean log loss per column.\n\nThe data comes in the familiar form of test and training files. Unlike other competitions, here we have two separate files for training predictors (train_features.csv) and targets (train_targets_scored.csv). Each row corresponds to a specific treatment."},{"metadata":{},"cell_type":"markdown","source":"## 1. Loading the dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\ntrain_target=pd.read_csv('../input/lish-moa/train_targets_scored.csv')\ntest=pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\nsubmission = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_cols=train_target.columns[1:]\ntarget_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds.loc[:, target_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train.shape:', train.shape)\nprint('train_target.shape:', train_target.shape)\nprint('test.shape:', test.shape)\nprint('submission.shape:', submission.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['cp_type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['cp_time'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['cp_dose'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The training and test sets include 876 coulmns.\n- sig_id: The unique id of the dataset.\n- cp_type: Catigorical feature which represents samples treated with a compound (cp_vehicle) or with a control perturbation (ctrl_vehicle); control perturbations have no MoAs.\n- cp_time: Catigorical feature which indicates treatment duration (24, 48, 72 hours). \t \t\n- cp_dose: Catigorical feature which represents high or low dose.\n- g-: Continous features which signify gene expression data.\n- c-: Continous features which signify cell viability data."},{"metadata":{},"cell_type":"markdown","source":"## 2. Features Engineering and EDA"},{"metadata":{},"cell_type":"markdown","source":"### 2.1. Target engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_target.head()\nprint (\"Shape of train target\",train_target.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The target are dummy encoded which will allow the computation of the predicted probability for each class. in Multi-label classification problem we predict variables and our target variables here are 206."},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = train_target.drop('sig_id',axis=1)\\\n.sum() \\\n.sort_values(ascending=False)\\\n.head(30)\\\n.sort_values()\\\n.plot(kind='barh',\n     figsize=(15, 10)\n     )\nax.set_title('Top 30 Scored Targets Classification Counts', fontsize=20)\nplt.show","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2. Handeling Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Missing values in training dataset:', train.isnull().sum().sum())\nprint('Missing values in testing dataset:', test.isnull().sum().sum())\nprint('Missing values in target dataset:', train_target.isnull().sum().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no missing values in the datasets"},{"metadata":{},"cell_type":"markdown","source":"### 2.3 Handeling Categorical Features"},{"metadata":{},"cell_type":"markdown","source":"As we mentioned above there are three catigrical features.\n- cp_type\n- cp_time\n- cp_dose\n\nWe will handel them using *Label encoding* approach. \n"},{"metadata":{},"cell_type":"markdown","source":"* **Why are all labels zero where cp_type = ctrl_vehicle ie for control?**\n\nCells set to zero because they are control/samples without compounds (no MoA). So, we are going to drop all rows of the vehicle treatment."},{"metadata":{"trusted":true},"cell_type":"code","source":"p_train=train.copy()\np_test=test.copy()\np_train_target=train_target.copy()\n#p_train.drop(p_train[p_train['cp_type']=='ctl_vehicle'].index, inplace = True)\n#p_test.drop(p_test[p_test['cp_type']=='ctl_vehicle'].index, inplace = True)\np_train['cp_time'] = p_train['cp_time'].map( {24: 1, 48: 2, 72: 3} ).astype(int)\np_test['cp_time'] = p_test['cp_time'].map( {24: 1, 48: 2, 72: 3} ).astype(int)\np_train['cp_type'] = p_train['cp_type'].map( {'trt_cp': 1, 'ctl_vehicle': 2} ).astype(int)\np_test['cp_type'] = p_test['cp_type'].map( {'trt_cp': 1, 'ctl_vehicle': 2} ).astype(int)\np_train['cp_dose'] = p_train['cp_dose'].map( {'D1': 1, 'D2': 2} ).astype(int)\np_test['cp_dose'] = p_test['cp_dose'].map( {'D1': 1, 'D2': 2} ).astype(int)\np_train.drop('sig_id',axis='columns', inplace=True)\np_test.drop('sig_id',axis='columns', inplace=True)\np_train_target.drop('sig_id',axis='columns', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we'll preprocess training and testing datasets using MinMaxScaler to scale each feature individually."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit scaler to joint train and test data\n#scaler = preprocessing.MinMaxScaler()\n#scaler.fit(p_train.append(p_test))\n\n#train_trans = scaler.transform(p_train)\n#test_trans = scaler.transform(p_test)\n\n#p_train = pd.DataFrame(train_trans, columns=p_train.columns)\n#p_test = pd.DataFrame(test_trans, columns=p_test.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3 Numeric feature engineering\n"},{"metadata":{},"cell_type":"markdown","source":"There are 872 numeric features devided to two categories; features represent the genes and features represent the cells."},{"metadata":{},"cell_type":"markdown","source":"- **Why are there 23k samples when there are only 5k drugs?**\n\n    A perturbagen ,which is a method of providing information about the operation of pathways and networks within a cell, is applied to a mixture of cell lines not to a single cell. also, one control could be used for many different drugs and even other drugs could be also used as controls in specific cases.\n"},{"metadata":{},"cell_type":"markdown","source":"#### **Interpreting Gene Expression Features**\n\nGene expression features are 772 and represent the mRNA level or in other words, the process of synthesizing a protein.\n\nGene features values are giving an insight whether a drug has an effect on the gene or no, where high values >2 or <-2 says there is a measurable effect on the gene unlike values close to zero."},{"metadata":{"trusted":true},"cell_type":"code","source":"g_features = [cols for cols in train.columns if cols.startswith('g-')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"color = ['dimgray','navy','purple','orangered', 'red', 'green' ,'mediumorchid', 'khaki', 'salmon', 'blue','cornflowerblue','mediumseagreen']\n \ncolor_ind=0\nn_row = 6\nn_col = 3\nn_sub = 1 \nplt.rcParams[\"legend.loc\"] = 'upper right'\nfig = plt.figure(figsize=(8,14))\nplt.subplots_adjust(left=-0.3, right=1.3,bottom=-0.3,top=1.3)\nfor i in (np.arange(0,6,1)):\n    plt.subplot(n_row, n_col, n_sub)\n    sns.kdeplot(train.loc[:,g_features[i]],color=color[color_ind],shade=True,\n                 label=['mean:'+str('{:.2f}'.format(train.loc[:,g_features[i]].mean()))\n                        +'  ''std: '+str('{:.2f}'.format(train.loc[:,g_features[i]].std()))])\n    \n    plt.xlabel(g_features[i])\n    plt.legend()                    \n    n_sub+=1\n    color_ind+=1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- **What is the cell viability features?**\n\ncell viability assays use multi markers to indicat active healthy cells in a population. also to optimize experimental conditions following treatment.\n\nand we have 100 cell-viability features (c-0 to c-99). Each cell-viability feature represents viability of one particular cell."},{"metadata":{"trusted":true},"cell_type":"code","source":"c_features = [cols for cols in train.columns if cols.startswith('c-')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_row = 6\nn_col = 3\nn_sub = 1 \nfig = plt.figure(figsize=(8,14))\nplt.subplots_adjust(left=-0.3, right=1.3,bottom=-0.3,top=1.3)\nplt.rcParams[\"legend.loc\"] = 'upper left'\nfor i in (np.arange(0,6,1)):\n    plt.subplot(n_row, n_col, n_sub)\n    sns.kdeplot(train.loc[:,c_features[i]],color=color[color_ind],shade=True,\n                 label=['mean:'+str('{:.2f}'.format(train.loc[:,c_features[i]].mean()))\n                        +'  ''std: '+str('{:.2f}'.format(train.loc[:,c_features[i]].std()))])\n    \n    plt.xlabel(c_features[i])\n    plt.legend()                    \n    n_sub+=1\n    color_ind+=1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. NN Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = p_train_target\nx_train = p_train\nx_test = p_test\nn_cols = x_train.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hypermeters\nSEED = 1234\nEPOCHS = 28\nBATCH_SIZE = 128\nFOLDS = 5\nREPEATS = 5\nLR = 0.0005\ntarget_cols=train_target.columns[1:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.1 Cross Validation and Keras Model Definition"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(resume_models = None, repeat_number = 0, folds = 5, skip_folds = 0):\n    \n    models = []\n    prediction = y_train.copy()\n    \n    # Enumarating in 5 folds\n    kfold = KFold(folds, shuffle = True)\n    # Splitting the training set to train and validaation set\n    for fold, (train_inx, v_inx) in enumerate(kfold.split(x_train)):\n        print('\\n')\n        print('-'*50)\n        print(f'Repeat:{repeat_number} Training Fold:{fold+1}')\n        \n        # Checkpointing with ReduceLROnPlateau to reduce learning rate then save the best model only\n        cb_lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'binary_crossentropy', factor = 0.4, patience = 2, verbose = 1, min_delta = 0.0001, mode = 'auto')\n        checkpoint_path = f'repeat:{repeat_number}_Fold:{fold}.hdf5'\n        cb_checkpt = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor = 'val_loss', verbose = 0, save_best_only = True, save_weights_only = True, mode = 'min')\n        \n        # Build the NN model\n        model = Sequential()\n        #three input layers with relu activation function\n        model.add(Dense(2048, input_dim=n_cols, activation='relu'))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.5))\n        model.add(Dense(2048,activation='relu'))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.5))\n        model.add(Dense(206, activation='sigmoid'))\n        # Compile model\n        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])        \n        #fit the model\n        model.fit(x_train.values[train_inx],y_train.values[train_inx],validation_data=(x_train.values[v_inx], y_train.values[v_inx]),callbacks = [cb_lr_schedule, cb_checkpt],epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=2)\n        \n        #load the checkpoimts\n        model.load_weights(checkpoint_path)\n        prediction.loc[v_inx, :] = model.predict(x_train.values[v_inx])\n        models.append(model)\n\n    return models, prediction","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.2 Model Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = []\nprediction = []\n# reproducability\nnp.random.seed(SEED)\nos.environ['PYTHONHASHSEED'] = str(SEED)\ntf.random.set_seed(SEED)\n\n#Repeat\nfor i in range(REPEATS):\n    m, oof = train(repeat_number = i, folds=FOLDS)\n    models = models + m\n    prediction.append(oof)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.3 Test Predictions and Save Submission\n"},{"metadata":{},"cell_type":"markdown","source":"Submissions are scored by the log loss:\n\n$\\Large \\text{log loss} = - \\frac{1}{M}\\sum_{m=1}^{M} \\frac{1}{N} \\sum_{i=1}^{N} \\left[ y_{i,m} \\log(\\hat{y}_{i,m}) + (1 - y_{i,m}) \\log(1 - \\hat{y}_{i,m})\\right]$\n\n* $N$ is the number of rows ($i=1,…,N$)\n* $M$ is the number of targets ($m=1,…,M$)\n* $\\large \\hat{y}_{i,m}$ is the predicted probability of the ith row and mth target\n* $\\large y_{i,m}$ is the ground truth of the ith row and mth target (1 for a positive response, 0 otherwise)\n* $log()$ is the natural logarithm"},{"metadata":{"trusted":true},"cell_type":"code","source":"def multi_log_loss(y_actual, y_pred):\n    y_pred = np.clip(y_pred, 1e-15, (1 - 1e-15))\n    score = - np.mean(np.mean(y_actual * np.log(y_pred) + (1 - y_actual) * np.log(1 - y_pred), axis=1))\n    return score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_preds = y_train.copy()\nmean_preds.loc[:, target_cols] = 0\nfor i, pred in enumerate(prediction):\n    print(f'Repeat {i + 1} Log Loss: {multi_log_loss(y_train, pred)}')\n    mean_preds.loc[:, target_cols] += pred[target_cols]\n\nmean_preds.loc[:, target_cols] /= len(prediction)\nprint(f'Mean Log Loss: {multi_log_loss(y_train, mean_preds)}')\nmean_preds.loc[x_train['cp_type'] == 0, target_cols] = 0\nprint(f\"Mean Log Loss (ctl adjusted): {multi_log_loss(y_train, mean_preds)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = submission.copy()\ntest_preds[ target_cols] = 0\nfor model in models:\n    test_preds.loc[:, target_cols] += model.predict(x_test)\ntest_preds.loc[:, target_cols] /= len(models)\ntest_preds.loc[x_test['cp_type'] == 0,  target_cols] = 0\ntest_preds.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}